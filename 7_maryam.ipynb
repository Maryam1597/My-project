{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3172037c-6bf7-41f1-b8d9-25f8bc7fc511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and initial preprocessing...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['HeartRate_Min', 'HeartRate_Max', 'HeartRate_Mean', 'SysBP_Min', 'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min', 'DiasBP_Max', 'DiasBP_Mean', 'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean', 'RespRate_Min', 'RespRate_Max', 'RespRate_Mean', 'TempC_Min', 'TempC_Max', 'TempC_Mean', 'SpO2_Min', 'SpO2_Max', 'SpO2_Mean', 'Glucose_Min', 'Glucose_Max', 'Glucose_Mean'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Select key features based on Kaggle notebook\u001b[39;00m\n\u001b[32m     33\u001b[39m selected_features = [\n\u001b[32m     34\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgender\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mLOSdays\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNumChartEvents\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNumNotes\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNumProcs\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     35\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mNumLabs\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNumMicroLabs\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNumRx\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33madmit_type\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33madmit_location\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mGlucose_Max\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mGlucose_Mean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mexpired\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     42\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInitial target distribution:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mexpired\u001b[39m\u001b[33m'\u001b[39m].value_counts()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClass ratio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mexpired\u001b[39m\u001b[33m'\u001b[39m].mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['HeartRate_Min', 'HeartRate_Max', 'HeartRate_Mean', 'SysBP_Min', 'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min', 'DiasBP_Max', 'DiasBP_Mean', 'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean', 'RespRate_Min', 'RespRate_Max', 'RespRate_Mean', 'TempC_Min', 'TempC_Max', 'TempC_Mean', 'SpO2_Min', 'SpO2_Max', 'SpO2_Mean', 'Glucose_Min', 'Glucose_Max', 'Glucose_Mean'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_auc_score, roc_curve, accuracy_score, \n",
    "                             precision_recall_curve, auc, f1_score, \n",
    "                             precision_score, recall_score, average_precision_score,\n",
    "                             brier_score_loss, log_loss)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --------------------------\n",
    "# 1. Data Loading & Initial Prep\n",
    "# --------------------------\n",
    "print(\"Loading data and initial preprocessing...\")\n",
    "df = pd.read_csv('mimic3c.csv')\n",
    "\n",
    "# Create target variable\n",
    "df['expired'] = df['ExpiredHospital'].astype(int)\n",
    "\n",
    "# Select key features based on Kaggle notebook\n",
    "selected_features = [\n",
    "    'age', 'gender', 'LOSdays', 'NumChartEvents', 'NumNotes', 'NumProcs',\n",
    "    'NumLabs', 'NumMicroLabs', 'NumRx', 'admit_type', 'admit_location',\n",
    "    'insurance', 'marital_status', 'ethnicity', 'HeartRate_Min', 'HeartRate_Max',\n",
    "    'HeartRate_Mean', 'SysBP_Min', 'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min',\n",
    "    'DiasBP_Max', 'DiasBP_Mean', 'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean',\n",
    "    'RespRate_Min', 'RespRate_Max', 'RespRate_Mean', 'TempC_Min', 'TempC_Max',\n",
    "    'TempC_Mean', 'SpO2_Min', 'SpO2_Max', 'SpO2_Mean', 'Glucose_Min',\n",
    "    'Glucose_Max', 'Glucose_Mean', 'expired'\n",
    "]\n",
    "\n",
    "df = df[selected_features]\n",
    "\n",
    "print(f\"Initial target distribution:\\n{df['expired'].value_counts()}\")\n",
    "print(f\"Class ratio: {df['expired'].mean():.4f}\")\n",
    "\n",
    "# --------------------------\n",
    "# 2. Data Cleaning & Preprocessing\n",
    "# --------------------------\n",
    "print(\"\\nPerforming data cleaning...\")\n",
    "\n",
    "# Handle missing values - simpler imputation\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = ['gender', 'admit_type', 'admit_location', 'insurance', 'marital_status', 'ethnicity']\n",
    "\n",
    "# Impute numerical features with median\n",
    "for col in numeric_cols:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "    \n",
    "# Impute categorical features with mode\n",
    "for col in categorical_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Feature transformations\n",
    "skewed_features = ['NumChartEvents', 'NumNotes', 'NumProcs', 'NumLabs', 'NumMicroLabs', 'NumRx']\n",
    "for feature in skewed_features:\n",
    "    df[feature] = np.log1p(df[feature])\n",
    "\n",
    "# --------------------------\n",
    "# 3. Feature Selection\n",
    "# --------------------------\n",
    "X = df.drop(columns=['expired'])\n",
    "y = df['expired']\n",
    "\n",
    "# Select top 30 features using ANOVA F-value\n",
    "selector = SelectKBest(f_classif, k=30)\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "selected_mask = selector.get_support()\n",
    "selected_features = X.columns[selected_mask]\n",
    "\n",
    "print(\"\\nSelected features:\")\n",
    "print(selected_features.tolist())\n",
    "\n",
    "X = pd.DataFrame(X_selected, columns=selected_features)\n",
    "\n",
    "# --------------------------\n",
    "# 4. Train-Test Split & Balancing\n",
    "# --------------------------\n",
    "# Split data before any balancing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nClass distribution before balancing:\")\n",
    "print(f\"Training: {Counter(y_train)}\")\n",
    "print(f\"Testing: {Counter(y_test)}\")\n",
    "\n",
    "# Apply SMOTE only to training data\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(f\"Training: {Counter(y_train_res)}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_res = scaler.fit_transform(X_train_res)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# --------------------------\n",
    "# 5. Model Training & Evaluation\n",
    "# --------------------------\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluate models\n",
    "results = []\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- Training {name} ---\")\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_proba = model.decision_function(X_test)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    pr_auc = average_precision_score(y_test, y_proba)\n",
    "    logloss = log_loss(y_test, y_proba)\n",
    "    brier = brier_score_loss(y_test, y_proba)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1\": f1,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"PR AUC\": pr_auc,\n",
    "        \"Log Loss\": logloss,\n",
    "        \"Brier Score\": brier\n",
    "    })\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_proba)\n",
    "    plt.figure()\n",
    "    plt.plot(recall_curve, precision_curve, label=name)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve: {name}')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'pr_curve_{name.lower().replace(\" \", \"_\")}.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure()\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Survived', 'Died'], \n",
    "                yticklabels=['Survived', 'Died'])\n",
    "    plt.title(f'Confusion Matrix: {name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'confusion_matrix_{name.lower().replace(\" \", \"_\")}.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}, PR AUC: {pr_auc:.4f}\")\n",
    "    print(f\"Log Loss: {logloss:.4f}, Brier Score: {brier:.4f}\")\n",
    "\n",
    "# ROC Curve for all models\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves: Model Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curves_comparison.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Results comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df)\n",
    "\n",
    "# --------------------------\n",
    "# 6. Hyperparameter Tuning (Logistic Regression)\n",
    "# --------------------------\n",
    "print(\"\\nTuning Logistic Regression...\")\n",
    "param_grid = {\n",
    "    'C': np.logspace(-3, 3, 7),\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "lr_tuner = GridSearchCV(\n",
    "    lr, param_grid, scoring='roc_auc', \n",
    "    cv=StratifiedKFold(5, shuffle=True, random_state=42),\n",
    "    n_jobs=-1, verbose=1\n",
    ")\n",
    "lr_tuner.fit(X_train_res, y_train_res)\n",
    "\n",
    "best_lr = lr_tuner.best_estimator_\n",
    "print(f\"Best parameters: {lr_tuner.best_params_}\")\n",
    "print(f\"Best ROC AUC: {lr_tuner.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate best model\n",
    "y_proba_lr = best_lr.predict_proba(X_test)[:, 1]\n",
    "y_pred_lr = best_lr.predict(X_test)\n",
    "\n",
    "print(\"\\nTuned Logistic Regression Performance:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_proba_lr):.4f}\")\n",
    "print(f\"PR AUC: {average_precision_score(y_test, y_proba_lr):.4f}\")\n",
    "\n",
    "# --------------------------\n",
    "# 7. Model Calibration\n",
    "# --------------------------\n",
    "print(\"\\nCalibrating model...\")\n",
    "calibrated_lr = CalibratedClassifierCV(best_lr, method='isotonic', cv=5)\n",
    "calibrated_lr.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_proba_cal = calibrated_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Reliability curve\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "    y_test, y_proba_cal, n_bins=10\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Calibrated LR\")\n",
    "plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "plt.xlabel(\"Mean predicted value\")\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "plt.title(\"Calibration Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('calibration_curve.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Compare calibration scores\n",
    "print(f\"Brier score (uncalibrated): {brier_score_loss(y_test, y_proba_lr):.4f}\")\n",
    "print(f\"Brier score (calibrated): {brier_score_loss(y_test, y_proba_cal):.4f}\")\n",
    "\n",
    "# --------------------------\n",
    "# 8. Feature Importance\n",
    "# --------------------------\n",
    "# Logistic Regression coefficients\n",
    "coefs = pd.Series(best_lr.coef_[0], index=selected_features)\n",
    "sorted_coefs = coefs.abs().sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=sorted_coefs.values, y=sorted_coefs.index, palette='viridis')\n",
    "plt.title('Top 20 Predictive Features (Logistic Regression)', fontsize=14)\n",
    "plt.xlabel('Absolute Coefficient Value')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop predictive features:\")\n",
    "print(sorted_coefs)\n",
    "\n",
    "# --------------------------\n",
    "# 9. Final Evaluation Report\n",
    "# --------------------------\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_proba, model_name):\n",
    "    \"\"\"Generate comprehensive evaluation report\"\"\"\n",
    "    # Classification metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='binary'\n",
    "    )\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "    pr_auc = average_precision_score(y_true, y_proba)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Calibration metrics\n",
    "    logloss = log_loss(y_true, y_proba)\n",
    "    brier = brier_score_loss(y_true, y_proba)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1,\n",
    "        'ROC AUC': roc_auc,\n",
    "        'PR AUC': pr_auc,\n",
    "        'Sensitivity': sensitivity,\n",
    "        'Specificity': specificity,\n",
    "        'Log Loss': logloss,\n",
    "        'Brier Score': brier,\n",
    "        'TP': tp,\n",
    "        'FP': fp,\n",
    "        'TN': tn,\n",
    "        'FN': fn\n",
    "    }\n",
    "\n",
    "# Evaluate both models\n",
    "final_results = [\n",
    "    evaluate_model(y_test, y_pred_lr, y_proba_lr, \"Logistic Regression (Uncalibrated)\"),\n",
    "    evaluate_model(y_test, calibrated_lr.predict(X_test), y_proba_cal, \"Logistic Regression (Calibrated)\")\n",
    "]\n",
    "\n",
    "# Create final report\n",
    "final_report = pd.DataFrame(final_results)\n",
    "print(\"\\nFinal Model Evaluation:\")\n",
    "print(final_report)\n",
    "\n",
    "# Save results to CSV\n",
    "final_report.to_csv('model_evaluation_results.csv', index=False)\n",
    "print(\"\\nAnalysis complete! All results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02271f0e-c0b8-491d-873e-9908ec9ffaf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d2da81-b84c-4af0-80cf-a6d05b6ab9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 11 features.\n",
      "Missing columns (skipped): ['Glucose_Mean', 'RespRate_Min', 'HeartRate_Min', 'SysBP_Mean', 'Glucose_Min', 'RespRate_Mean', 'SpO2_Max', 'SpO2_Mean', 'TempC_Min', 'HeartRate_Mean', 'DiasBP_Max', 'TempC_Max', 'HeartRate_Max', 'DiasBP_Min', 'DiasBP_Mean', 'SysBP_Max', 'MeanBP_Min', 'MeanBP_Mean', 'SysBP_Min', 'RespRate_Max', 'SpO2_Min', 'Glucose_Max', 'MeanBP_Max', 'TempC_Mean']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target column 'expired' not found in dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Ensure target exists\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target_col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df.columns:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTarget column \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found in dataset.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# === Subset the Data ===\u001b[39;00m\n\u001b[32m     50\u001b[39m df = df[available_features + [target_col]]\n",
      "\u001b[31mValueError\u001b[39m: Target column 'expired' not found in dataset."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix,\n",
    "    ConfusionMatrixDisplay, roc_curve\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "\n",
    "# === Load Dataset ===\n",
    "df = pd.read_csv('mimic3c.csv')\n",
    "\n",
    "# === Define Target and Potential Features ===\n",
    "target_col = 'expired'  # Adjust if your target column has a different name\n",
    "potential_features = [\n",
    "    'age', 'gender', 'LOSdays', 'NumChartEvents', 'NumNotes', 'NumProcs',\n",
    "    'NumLabs', 'NumMicroLabs', 'NumRx', 'admit_type', 'admit_location',\n",
    "    'HeartRate_Min', 'HeartRate_Max', 'HeartRate_Mean', 'SysBP_Min',\n",
    "    'SysBP_Max', 'SysBP_Mean', 'DiasBP_Min', 'DiasBP_Max', 'DiasBP_Mean',\n",
    "    'MeanBP_Min', 'MeanBP_Max', 'MeanBP_Mean', 'RespRate_Min',\n",
    "    'RespRate_Max', 'RespRate_Mean', 'TempC_Min', 'TempC_Max', 'TempC_Mean',\n",
    "    'SpO2_Min', 'SpO2_Max', 'SpO2_Mean', 'Glucose_Min', 'Glucose_Max',\n",
    "    'Glucose_Mean'\n",
    "]\n",
    "\n",
    "# === Keep Only Available Features ===\n",
    "available_features = [col for col in potential_features if col in df.columns]\n",
    "missing_features = list(set(potential_features) - set(available_features))\n",
    "print(f\"Using {len(available_features)} features.\")\n",
    "if missing_features:\n",
    "    print(\"Missing columns (skipped):\", missing_features)\n",
    "\n",
    "# Ensure target exists\n",
    "if target_col not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target_col}' not found in dataset.\")\n",
    "\n",
    "# === Subset the Data ===\n",
    "df = df[available_features + [target_col]]\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# === Impute and Scale ===\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# === Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# === Define Classifiers ===\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'SGD': SGDClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# === Train and Evaluate ===\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    probas = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else model.decision_function(X_test)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': accuracy_score(y_test, preds),\n",
    "        'precision': precision_score(y_test, preds),\n",
    "        'recall': recall_score(y_test, preds),\n",
    "        'f1': f1_score(y_test, preds),\n",
    "        'roc_auc': roc_auc_score(y_test, probas)\n",
    "    }\n",
    "\n",
    "# === Show Performance ===\n",
    "res_df = pd.DataFrame(results).T.sort_values('roc_auc', ascending=False)\n",
    "print(\"\\nModel Performance:\")\n",
    "print(res_df)\n",
    "\n",
    "# === Best Model: Random Forest Feature Importance ===\n",
    "rf = models['RandomForest']\n",
    "importances = rf.feature_importances_\n",
    "feat_names = X.columns\n",
    "sorted_idx = np.argsort(importances)[-15:]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feat_names[sorted_idx], importances[sorted_idx])\n",
    "plt.title(\"Top 15 Important Features (Random Forest)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === ROC Curve for Random Forest ===\n",
    "y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, label=f'ROC AUC = {roc_auc_score(y_test, y_prob):.3f}')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Random Forest')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# === Confusion Matrix ===\n",
    "ConfusionMatrixDisplay.from_estimator(rf, X_test, y_test)\n",
    "plt.title(\"Confusion Matrix - Random Forest\")\n",
    "plt.show()\n",
    "\n",
    "# === Deep Neural Network ===\n",
    "nn = Sequential([\n",
    "    Dense(256, activation='relu', input_dim=X_train.shape[1]),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "nn.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = nn.fit(\n",
    "    X_train, y_train, validation_split=0.2,\n",
    "    epochs=30, batch_size=128, verbose=0\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title(\"NN Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate NN\n",
    "y_pred_nn = (nn.predict(X_test).flatten() > 0.5).astype(int)\n",
    "y_prob_nn = nn.predict(X_test).flatten()\n",
    "\n",
    "print(\"\\nNeural Network Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nn))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_nn))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_nn))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_nn))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3551dfe-b391-462c-9e80-181e7d20d416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hadm_id', 'gender', 'age', 'LOSdays', 'admit_type', 'admit_location', 'AdmitDiagnosis', 'insurance', 'religion', 'marital_status', 'ethnicity', 'NumCallouts', 'NumDiagnosis', 'NumProcs', 'AdmitProcedure', 'NumCPTevents', 'NumInput', 'NumLabs', 'NumMicroLabs', 'NumNotes', 'NumOutput', 'NumRx', 'NumProcEvents', 'NumTransfers', 'NumChartEvents', 'ExpiredHospital', 'TotalNumInteract', 'LOSgroupNum']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not find a suitable target column (e.g., expired, death, mortality).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m possible_targets = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df.columns \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mexpire\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mmortality\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mdeath\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col]\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m possible_targets:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCould not find a suitable target column (e.g., expired, death, mortality).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m target_col = possible_targets[\u001b[32m0\u001b[39m]\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing target column: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Could not find a suitable target column (e.g., expired, death, mortality)."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# === Load Data ===\n",
    "df = pd.read_csv(\"mimic3c.csv\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "\n",
    "# === Step 1: Define working features ===\n",
    "available_features = [\n",
    "    'age', 'gender', 'LOSdays', 'NumChartEvents', 'NumNotes', \n",
    "    'NumProcs', 'NumLabs', 'NumMicroLabs', 'NumRx', \n",
    "    'admit_type', 'admit_location'\n",
    "]\n",
    "\n",
    "# === Step 2: Infer the actual target column ===\n",
    "possible_targets = [col for col in df.columns if 'expire' in col or 'mortality' in col or 'death' in col]\n",
    "if not possible_targets:\n",
    "    raise ValueError(\"Could not find a suitable target column (e.g., expired, death, mortality).\")\n",
    "target_col = possible_targets[0]\n",
    "print(f\"Using target column: {target_col}\")\n",
    "\n",
    "# === Step 3: Prepare Data ===\n",
    "df = df[available_features + [target_col]]\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Impute & scale\n",
    "X = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(X), columns=X.columns)\n",
    "X = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === Step 4: Train Random Forest ===\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "# Plot Feature Importance\n",
    "importances = rf.feature_importances_\n",
    "sorted_idx = np.argsort(importances)\n",
    "plt.barh(X.columns[sorted_idx], importances[sorted_idx])\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Step 5: Deep Neural Network ===\n",
    "nn = Sequential([\n",
    "    Dense(128, activation='relu', input_dim=X.shape[1]),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "nn.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = nn.fit(X_train, y_train, validation_split=0.2, epochs=30, batch_size=64, verbose=0)\n",
    "\n",
    "# NN Evaluation\n",
    "y_pred_nn = (nn.predict(X_test).flatten() > 0.5).astype(int)\n",
    "y_prob_nn = nn.predict(X_test).flatten()\n",
    "print(\"\\nNeural Network Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nn))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_nn))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_nn))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_nn))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_nn))\n",
    "\n",
    "# NN Loss Curve\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Neural Network Training Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "713cfe67-816e-4f40-af0d-af417a98412d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'F'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m y = df[target_col]\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Impute and scale\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m X = pd.DataFrame(\u001b[43mSimpleImputer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, columns=X.columns)\n\u001b[32m     38\u001b[39m X = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Train-test split\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\myenv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\myenv\\Lib\\site-packages\\sklearn\\base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\myenv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\myenv\\Lib\\site-packages\\sklearn\\impute\\_base.py:434\u001b[39m, in \u001b[36mSimpleImputer.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    416\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    418\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the imputer on `X`.\u001b[39;00m\n\u001b[32m    419\u001b[39m \n\u001b[32m    420\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    432\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m    433\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    436\u001b[39m     \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[32m    437\u001b[39m     \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[32m    438\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\myenv\\Lib\\site-packages\\sklearn\\impute\\_base.py:361\u001b[39m, in \u001b[36mSimpleImputer._validate_input\u001b[39m\u001b[34m(self, X, in_fit)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcould not convert\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n\u001b[32m    356\u001b[39m     new_ve = \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    357\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m strategy with non-numeric data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    358\u001b[39m             \u001b[38;5;28mself\u001b[39m.strategy, ve\n\u001b[32m    359\u001b[39m         )\n\u001b[32m    360\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ve\n",
      "\u001b[31mValueError\u001b[39m: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'F'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# === Load Data ===\n",
    "df = pd.read_csv(\"mimic3c.csv\")\n",
    "\n",
    "# === Define available features ===\n",
    "available_features = [\n",
    "    'age', 'gender', 'LOSdays', 'NumChartEvents', 'NumNotes',\n",
    "    'NumProcs', 'NumLabs', 'NumMicroLabs', 'NumRx',\n",
    "    'admit_type', 'admit_location'\n",
    "]\n",
    "\n",
    "# === Define target column ===\n",
    "target_col = 'ExpiredHospital'\n",
    "\n",
    "# === Validate column exists ===\n",
    "if target_col not in df.columns:\n",
    "    raise ValueError(f\"Target column '{target_col}' not found.\")\n",
    "\n",
    "# === Prepare features and target ===\n",
    "df = df[available_features + [target_col]]\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Impute and scale\n",
    "X = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(X), columns=X.columns)\n",
    "X = pd.DataFrame(StandardScaler().fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# === Random Forest ===\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"🎯 Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "# Feature importance\n",
    "importances = rf.feature_importances_\n",
    "sorted_idx = np.argsort(importances)\n",
    "plt.barh(X.columns[sorted_idx], importances[sorted_idx])\n",
    "plt.title(\"Feature Importance (Random Forest)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, label=f'ROC AUC = {roc_auc_score(y_test, y_prob):.3f}')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Neural Network ===\n",
    "nn = Sequential([\n",
    "    Dense(128, activation='relu', input_dim=X.shape[1]),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "nn.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = nn.fit(X_train, y_train, validation_split=0.2, epochs=30, batch_size=64, verbose=0)\n",
    "\n",
    "# NN evaluation\n",
    "y_pred_nn = (nn.predict(X_test).flatten() > 0.5).astype(int)\n",
    "y_prob_nn = nn.predict(X_test).flatten()\n",
    "\n",
    "print(\"\\n🤖 Neural Network Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nn))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_nn))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_nn))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred_nn))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob_nn))\n",
    "\n",
    "# NN loss plot\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title(\"Neural Network Training Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a46b9-d592-4882-8221-d5d19273983d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
